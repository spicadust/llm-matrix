{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRITON_LIBCUDA_PATH: /nix/store/z8ac4sgxc4h86zfmlz7yi0kkv95wgz84-graphics-drivers/lib\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify the path is set\n",
    "print(\"TRITON_LIBCUDA_PATH:\", os.getenv(\"TRITON_LIBCUDA_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spica/Repos/megaDNA_matrix/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 25/25 [00:00<00:00, 235.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra keys in state_dict: {'blocks.17.mixer.dense._extra_state', 'blocks.3.mixer.dense._extra_state', 'unembed.weight', 'blocks.24.mixer.dense._extra_state', 'blocks.10.mixer.dense._extra_state'}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from evo2 import Evo2\n",
    "\n",
    "evo2_model = Evo2(\"evo2_1b_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "sequence = \"ACGTAG\"\n",
    "input_ids = (\n",
    "    torch.tensor(\n",
    "        evo2_model.tokenizer.tokenize(sequence),\n",
    "        dtype=torch.int,\n",
    "    )\n",
    "    .unsqueeze(0)\n",
    "    .to(\"cuda:0\")\n",
    ")\n",
    "\n",
    "layer_name = \"blocks.24.mlp.l3\"\n",
    "\n",
    "outputs, embeddings = evo2_model(input_ids, return_embeddings=True, layer_names=[layer_name])\n",
    "\n",
    "print(\"Embeddings shape: \", embeddings[layer_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_matrix = list(SeqIO.parse(\"../dataset/matrix_genomes_11k.fasta\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [30:16<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1024 sequences\n",
      "Embeddings array shape: (1024, 1920)\n",
      "Number of headers: 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all sequences in the FASTA file and extract embeddings\n",
    "\n",
    "# Create lists to store results and failed sequences\n",
    "results = []\n",
    "failed_sequences = []\n",
    "\n",
    "# Process each sequence\n",
    "for record in tqdm(seq_matrix):\n",
    "    try:\n",
    "        # Extract sequence and header\n",
    "        sequence = str(record.seq)\n",
    "        header = record.description\n",
    "\n",
    "        # Make sure GPU memory is cleared before processing\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Tokenize and get embeddings\n",
    "        input_ids = (\n",
    "            torch.tensor(\n",
    "                evo2_model.tokenizer.tokenize(sequence),\n",
    "                dtype=torch.int,\n",
    "            )\n",
    "            .unsqueeze(0)\n",
    "            .to(\"cuda:0\")\n",
    "        )\n",
    "\n",
    "        layer_name = \"blocks.24.mlp.l3\"\n",
    "\n",
    "        # Get embeddings with explicit dtype to avoid BFloat16 issues\n",
    "        with torch.amp.autocast(\"cuda\", enabled=False):\n",
    "            outputs, embeddings = evo2_model(\n",
    "                input_ids, return_embeddings=True, layer_names=[layer_name]\n",
    "            )\n",
    "\n",
    "        # Extract the embeddings tensor and ensure it's float32\n",
    "        embedding_tensor = embeddings[layer_name].to(torch.float32)\n",
    "\n",
    "        # Average over the sequence length dimension to get a 1920-dim vector\n",
    "        # Shape goes from [1, n, 1920] to [1, 1920] to [1920]\n",
    "        avg_embedding = embedding_tensor.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "        # Store results\n",
    "        results.append({\"header\": header, \"embedding\": avg_embedding})\n",
    "\n",
    "        # Clear GPU cache to free memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sequence {header}: {e}\")\n",
    "        # Record the failed sequence\n",
    "        failed_sequences.append(header)\n",
    "        # Force GPU memory cleanup\n",
    "        torch.cuda.empty_cache()\n",
    "        continue\n",
    "\n",
    "# Extract headers\n",
    "headers = [r[\"header\"] for r in results]\n",
    "\n",
    "# Create a numpy array of all embeddings\n",
    "embeddings_array = np.stack([r[\"embedding\"] for r in results])\n",
    "\n",
    "print(f\"Processed {len(results)} sequences\")\n",
    "print(f\"Embeddings array shape: {embeddings_array.shape}\")\n",
    "print(f\"Number of headers: {len(headers)}\")\n",
    "\n",
    "# Save embeddings and headers with model-specific names\n",
    "np.save(\"../results/embeddings_evo2_matrix_small.npy\", embeddings_array)\n",
    "pd.DataFrame({\"header\": headers}).to_csv(\"../results/headers_evo2_matrix_small.csv\", index=False)\n",
    "\n",
    "# Save failed sequences\n",
    "if failed_sequences:\n",
    "    print(f\"Failed to process {len(failed_sequences)} sequences\")\n",
    "    pd.DataFrame({\"header\": failed_sequences}).to_csv(\n",
    "        \"../results/failed_sequences_evo2_matrix_small.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
